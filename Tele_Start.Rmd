---
title: "Group 1 Project 1: Telemarketing"
author: "Aakash Bharat, Maegan DeSmet, Ishan Goel, Doyeon Kim, Raamiz Qureshi"
date: "10/22/2022"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

str(tele_norm)
```


```{r}
library(neuralnet)
library(class)
library(caret)
library(gmodels)
```

# Step 1: K-Means Clustering
```{r}
# custom normalization function

kmeans_tele = telemm # Make a copy

kmeans_tele$y = NULL # Remove y column

kmeans_tele_scaled = as.data.frame(lapply(kmeans_tele, scale))

# Run K-Means Clusters
set.seed(0)
tele_clusters <- kmeans(kmeans_tele_scaled, 5)
```

## Look at K-Means Data

```{r}
str(tele_clusters)

tele_clusters$size
tele_clusters$centers
```

## Aggregate Data

```{r}
# telemm is the cleaned up tele data with all factors converted
# to dummies (e.g. y gets turned into yyes)
telemm$cluster = tele_clusters$cluster
tele$cluster = tele_clusters$cluster
tele_norm$cluster = tele_clusters$cluster
clusteredSuccessRates =
  aggregate(data = telemm, yyes ~ cluster, mean)
clusteredSuccessRates
tele_clusters$size

# Weighted average to verify total success rate is ~11%
weighted.mean(clusteredSuccessRates$yyes, tele_clusters$size)
```

## Create Train and Test Data

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train_norm <-
  tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test_norm <-
  tele_norm[test_set, -match("yyes",names(tele_norm))]

tele_train_reg = tele[-test_set,]# -match("y",names(tele))]
tele_test_reg = tele[test_set,  -match("y",names(tele))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels_norm <- tele_norm[-test_set, "yyes"]
tele_test_labels_norm <- tele_norm[test_set, "yyes"]

tele_train_labels_reg <- tele[-test_set, "y"]
tele_test_labels_reg <- tele[test_set, "y"]
```


# Step 2: Logarithmic, KNN, and ANN

## Separate Clusters

```{r}
# Get clusters 1, 3, and 4 with logical indexing
tc1_train_norm = tele_train_norm[tele_train_norm$cluster == 1,]
tc3_train_norm = tele_train_norm[tele_train_norm$cluster == 3,]
tc4_train_norm = tele_train_norm[tele_train_norm$cluster == 4,]

tc1_train_reg = tele_train_reg[tele_train_reg$cluster == 1,]
tc3_train_reg = tele_train_reg[tele_train_reg$cluster == 3,]
tc4_train_reg = tele_train_reg[tele_train_reg$cluster == 4,]

tc1_test_norm = tele_test_norm[tele_test_norm$cluster == 1,]
tc3_test_norm = tele_test_norm[tele_test_norm$cluster == 3,]
tc4_test_norm = tele_test_norm[tele_test_norm$cluster == 4,]

tc1_test_reg = tele_test_reg[tele_test_reg$cluster == 1,]
tc3_test_reg = tele_test_reg[tele_test_reg$cluster == 3,]
tc4_test_reg = tele_test_reg[tele_test_reg$cluster == 4,]

tc1_train_labels_norm =
  tele_train_labels_norm[tele_train_norm$cluster == 1]
tc3_train_labels_norm =
  tele_train_labels_norm[tele_train_norm$cluster == 3]
tc4_train_labels_norm =
  tele_train_labels_norm[tele_train_norm$cluster == 4]

tc1_test_labels_norm =
  tele_test_labels_norm[tele_test_norm$cluster == 1]
tc3_test_labels_norm =
  tele_test_labels_norm[tele_test_norm$cluster == 3]
tc4_test_labels_norm =
  tele_test_labels_norm[tele_test_norm$cluster == 4]

# Clusters 2 and 5 are already above 17%
```


## Cluster 1

### Logistic
```{r}
tc1_log = glm(formula = y ~ .,
              data = tc1_train_reg,
              family = "binomial")

tc1_log_model = predict.glm(tc1_log,
              newdata = tc1_test_reg,
              type = "response")
tc1_log_model = ifelse(tc1_log_model > 0.5, 1, 0)

```

### K-Nearest Neighbors
```{r}
tc1_knn_model = knn(train = tc1_train_norm,
                    test = tc1_test_norm,
                      cl = tc1_train_labels_norm, k = 101)

```

### Artificial Neural Net
```{r, cache = TRUE}
# Put back yyes column in copy of tc1_train_norm
tc1_train_with_yyes = tc1_train_norm
tc1_train_with_yyes$yyes = as.numeric(tc1_train_reg$y) - 1

tc1_ann = neuralnet(formula = yyes ~ .,
                        data = tc1_train_with_yyes,
                        hidden = 3)
```


```{r}
tc1_ann_model = predict(tc1_ann, newdata = tc1_test_norm,
                        type = "response")

tc1_ann_model = ifelse(tc1_ann_model > 0.5, 1, 0)
```

### Combine Models

```{r}
# Add 3 models together to count "votes" for Yes
tc1_knn_model = as.numeric(tc1_knn_model)
tc1_combine_model = tc1_ann_model + tc1_knn_model + tc1_log_model
tc1_combine_model = ifelse(tc1_combine_model >= 2, 1, 0)
```

## Cluster 3

### Logistic
```{r}
tc3_log = glm(formula = y ~ .,
              data = tc3_train_reg,
              family = "binomial")

tc3_log_model = predict.glm(tc3_log,
              newdata = tc3_test_reg,
              type = "response")
tc3_log_model = ifelse(tc3_log_model > 0.5, 1, 0)

```

### K-Nearest Neighbors
```{r}
tc3_knn_model = knn(train = tc3_train_norm,
                    test = tc3_test_norm,
                      cl = tc3_train_labels_norm, k = 53)

```

### Artificial Neural Net
```{r, cache = TRUE}
# Put back yyes column in copy of tc3_train_norm
tc3_train_with_yyes = tc3_train_norm
tc3_train_with_yyes$yyes = as.numeric(tc3_train_reg$y) - 1

tc3_ann = neuralnet(formula = yyes ~ .,
                        data = tc3_train_with_yyes,
                        hidden = 3)
```


```{r}
tc3_ann_model = predict(tc3_ann, newdata = tc3_test_norm,
                        type = "response")

tc3_ann_model = ifelse(tc3_ann_model > 0.5, 1, 0)
```

### Combine Models

```{r}
# Add 3 models together to count "votes" for Yes
tc3_knn_model = as.numeric(tc3_knn_model)
tc3_combine_model = tc3_ann_model + tc3_knn_model + tc3_log_model
tc3_combine_model = ifelse(tc3_combine_model >= 2, 1, 0)
```

## Cluster 4

### Logistic
```{r}
tc4_log = glm(formula = y ~ .,
              data = tc4_train_reg,
              family = "binomial")

tc4_log_model = predict.glm(tc4_log,
              newdata = tc4_test_reg,
              type = "response")
tc4_log_model = ifelse(tc4_log_model > 0.5, 1, 0)

```

### K-Nearest Neighbors
```{r}
tc4_knn_model = knn(train = tc4_train_norm,
                    test = tc4_test_norm,
                      cl = tc4_train_labels_norm, k = 47)

```

### Artificial Neural Net
```{r, cache = TRUE}
# Put back yyes column in copy of tc4_train_norm
tc4_train_with_yyes = tc4_train_norm
tc4_train_with_yyes$yyes = as.numeric(tc4_train_reg$y) - 1

tc4_ann = neuralnet(formula = yyes ~ .,
                        data = tc4_train_with_yyes,
                        hidden = 3)
```


```{r}
tc4_ann_model = predict(tc4_ann, newdata = tc4_test_norm,
                        type = "response")

tc4_ann_model = ifelse(tc4_ann_model > 0.5, 1, 0)
```

### Combine Models

```{r}
# Add 3 models together to count "votes" for Yes
tc4_knn_model = as.numeric(tc4_knn_model)
tc4_combine_model = tc4_ann_model + tc4_knn_model + tc4_log_model
tc4_combine_model = ifelse(tc4_combine_model >= 2, 1, 0)
```

# Step 3: Combine Everything

```{r}
# final model is first a copy of tc1 combine model
# so that final model is the correct length
final_model = tc1_combine_model
# Make full combine model filled with zeroes
final_model[final_model == 0] = 0

for (i in 1:nrows(final_model)) {
  # Call everyone in clusters 2 and 5
  if (tele_test_reg$cluster[i] == 2 |
      tele_test_reg$cluster[i] == 5) {
    final_model[i] = 1
  }
  # Use the model predictions for remaining clusters
  else if (tele_test_reg$cluster[i] == 1) {
    final_model[i] = tc1_combine_model[i]
  }
  else if (tele_test_reg$cluster[i] == 3) {
    final_model[i] = tc3_combine_model[i]
  }
  else if (tele_test_reg$cluster[i] == 4) {
    final_model[i] = tc4_combine_model[i]
  }
}
```

