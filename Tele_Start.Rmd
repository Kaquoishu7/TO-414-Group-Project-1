---
title: "HW6 Telemarketing"
author: "Enter Your Name Here"
date: "3/22/2020"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

str(tele_norm)
```


## Getting Train and Test Samples

```{r}
# # Selects 10000 random rows for test data
# set.seed(12345)
# test_set <- sample(1:nrow(tele_norm), 10000)
# # Depending on R-version and computer, different rows may be selected.
# # If that happens, results are different.
# 
# # Create a train set and test set
# #First the predictors - all columns except the yyes column
# tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
# tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]
# 
# #Now the response (aka Labels) - only the yyes column
# tele_train_labels <- tele_norm[-test_set, "yyes"]
# tele_test_labels <- tele_norm[test_set, "yyes"]

```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

```{r}
library(neuralnet)
library(class)
library(caret)
library(gmodels)
```

# Step 1: K-Means Clustering
```{r}
# custom normalization function

kmeans_tele = telemm # Make a copy

kmeans_tele$y = NULL # Remove y column

kmeans_tele_scaled = as.data.frame(lapply(kmeans_tele, scale))

# Run K-Means Clusters
set.seed(0)
tele_clusters <- kmeans(kmeans_tele_scaled, 5)
```

## Look at K-Means Data

```{r}
str(tele_clusters)

tele_clusters$size
tele_clusters$centers
```

## Aggregate Data

```{r}
# telemm is the cleaned up tele data with all factors converted
# to dummies (e.g. y gets turned into yyes)
telemm$cluster = tele_clusters$cluster
clusteredSuccessRates =
  aggregate(data = telemm, yyes ~ cluster, mean)
clusteredSuccessRates
tele_clusters$size

# Weighted average to verify total success rate is ~11%
weighted.mean(clusteredSuccessRates$yyes, tele_clusters$size)
```



```{r}
# test_indices = 1:round(nrow(tele_norm) / 5)
# tele_train = tele_norm[-test_indices,]
# tele_test = tele_norm[test_indices,]
```


```{r, cache = TRUE}
# answerModel = neuralnet(formula = yyes ~ .,
#                         data = tele_train,
#                         hidden = 7)
```

```{r}
#plot(answerModel)
```

```{r}
# predictionANN = predict(answerModel, newdata = tele_test,
#                         type = "response")
# 
# predictionANN = ifelse(predictionANN >= 0.25, 1, 0)
# 
# tele_label = tele_test[1:nrow(tele_test), "yyes"]
# 
# CrossTable(x = tele_label, y = predictionANN, 
#            prop.chisq=FALSE)
# 
# confusionMatrix(as.factor(predictionANN), as.factor(tele_label))

```

